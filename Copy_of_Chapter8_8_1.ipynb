{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy_of_Chapter8_8_1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aasifshahzad/colab/blob/main/Copy_of_Chapter8_8_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TZ5FHk5Ss6_"
      },
      "source": [
        "import numpy as np\n",
        "def reweight_distribution(original_distribution, temperature=0.5):\n",
        "  distribution = np.log(original_distribution) / temperature\n",
        "  distribution = np.exp(distribution)\n",
        "  return distribution / np.sum(distribution)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "wRKJKHC9Z_2R",
        "outputId": "fbda47c0-cd45-4a38-9708-80d8b7bcd9cf"
      },
      "source": [
        "text = \"\"\"\n",
        "PREFACE\n",
        "\n",
        "\n",
        "SUPPOSING that Truth is a woman--what then? Is there not ground\n",
        "for suspecting that all philosophers, in so far as they have been\n",
        "dogmatists, have failed to understand women--that the terrible\n",
        "seriousness and clumsy importunity with which they have usually paid\n",
        "their addresses to Truth, have been unskilled and unseemly methods for\n",
        "winning a woman? Certainly she has never allowed herself to be won; and\n",
        "at present every kind of dogma stands with sad and discouraged mien--IF,\n",
        "indeed, it stands at all! For there are scoffers who maintain that it\n",
        "has fallen, that all dogma lies on the ground--nay more, that it is at\n",
        "its last gasp. But to speak seriously, there are good grounds for hoping\n",
        "that all dogmatizing in philosophy, whatever solemn, whatever conclusive\n",
        "and decided airs it has assumed, may have been only a noble puerilism\n",
        "and tyronism; and probably the time is at hand when it will be once\n",
        "and again understood WHAT has actually sufficed for the basis of such\n",
        "imposing and absolute philosophical edifices as the dogmatists have\n",
        "hitherto reared: perhaps some popular superstition of immemorial time\n",
        "(such as the soul-superstition, which, in the form of subject- and\n",
        "ego-superstition, has not yet ceased doing mischief): perhaps some\n",
        "play upon words, a deception on the part of grammar, or an\n",
        "audacious generalization of very restricted, very personal, very\n",
        "human--all-too-human facts. The philosophy of the dogmatists, it is to\n",
        "be hoped, was only a promise for thousands of years afterwards, as was\n",
        "astrology in still earlier times, in the service of which probably more\n",
        "labour, gold, acuteness, and patience have been spent than on any\n",
        "actual science hitherto: we owe to it, and to its \"super-terrestrial\"\n",
        "pretensions in Asia and Egypt, the grand style of architecture. It seems\n",
        "that in order to inscribe themselves upon the heart of humanity with\n",
        "everlasting claims, all great things have first to wander about the\n",
        "earth as enormous and awe-inspiring caricatures: dogmatic philosophy has\n",
        "been a caricature of this kind--for instance, the Vedanta doctrine in\n",
        "Asia, and Platonism in Europe. Let us not be ungrateful to it, although\n",
        "it must certainly be confessed that the worst, the most tiresome,\n",
        "and the most dangerous of errors hitherto has been a dogmatist\n",
        "error--namely, Plato's invention of Pure Spirit and the Good in Itself.\n",
        "But now when it has been surmounted, when Europe, rid of this nightmare,\n",
        "can again draw breath freely and at least enjoy a healthier--sleep,\n",
        "we, WHOSE DUTY IS WAKEFULNESS ITSELF, are the heirs of all the strength\n",
        "which the struggle against this error has fostered. It amounted to\n",
        "the very inversion of truth, and the denial of the PERSPECTIVE--the\n",
        "fundamental condition--of life, to speak of Spirit and the Good as Plato\n",
        "spoke of them; indeed one might ask, as a physician: \"How did such a\n",
        "malady attack that finest product of antiquity, Plato? Had the wicked\n",
        "Socrates really corrupted him? Was Socrates after all a corrupter of\n",
        "youths, and deserved his hemlock?\" But the struggle against Plato,\n",
        "or--to speak plainer, and for the \"people\"--the struggle against\n",
        "the ecclesiastical oppression of millenniums of Christianity (FOR\n",
        "CHRISTIANITY IS PLATONISM FOR THE \"PEOPLE\"), produced in Europe\n",
        "a magnificent tension of soul, such as had not existed anywhere\n",
        "previously; with such a tensely strained bow one can now aim at the\n",
        "furthest goals. As a matter of fact, the European feels this tension as\n",
        "a state of distress, and twice attempts have been made in grand style to\n",
        "unbend the bow: once by means of Jesuitism, and the second time by means\n",
        "of democratic enlightenment--which, with the aid of liberty of the press\n",
        "and newspaper-reading, might, in fact, bring it about that the spirit\n",
        "would not so easily find itself in \"distress\"! (The Germans invented\n",
        "gunpowder--all credit to them! but they again made things square--they\n",
        "invented printing.) But we, who are neither Jesuits, nor democrats,\n",
        "nor even sufficiently Germans, we GOOD EUROPEANS, and free, VERY free\n",
        "spirits--we have it still, all the distress of spirit and all the\n",
        "tension of its bow! And perhaps also the arrow, the duty, and, who\n",
        "knows? THE GOAL TO AIM AT....\n",
        "\n",
        "\n",
        "\"\"\".lower()\n",
        "print(len(text))\n",
        "text"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4183\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\npreface\\n\\n\\nsupposing that truth is a woman--what then? is there not ground\\nfor suspecting that all philosophers, in so far as they have been\\ndogmatists, have failed to understand women--that the terrible\\nseriousness and clumsy importunity with which they have usually paid\\ntheir addresses to truth, have been unskilled and unseemly methods for\\nwinning a woman? certainly she has never allowed herself to be won; and\\nat present every kind of dogma stands with sad and discouraged mien--if,\\nindeed, it stands at all! for there are scoffers who maintain that it\\nhas fallen, that all dogma lies on the ground--nay more, that it is at\\nits last gasp. but to speak seriously, there are good grounds for hoping\\nthat all dogmatizing in philosophy, whatever solemn, whatever conclusive\\nand decided airs it has assumed, may have been only a noble puerilism\\nand tyronism; and probably the time is at hand when it will be once\\nand again understood what has actually sufficed for the basis of such\\nimposing and absolute philosophical edifices as the dogmatists have\\nhitherto reared: perhaps some popular superstition of immemorial time\\n(such as the soul-superstition, which, in the form of subject- and\\nego-superstition, has not yet ceased doing mischief): perhaps some\\nplay upon words, a deception on the part of grammar, or an\\naudacious generalization of very restricted, very personal, very\\nhuman--all-too-human facts. the philosophy of the dogmatists, it is to\\nbe hoped, was only a promise for thousands of years afterwards, as was\\nastrology in still earlier times, in the service of which probably more\\nlabour, gold, acuteness, and patience have been spent than on any\\nactual science hitherto: we owe to it, and to its \"super-terrestrial\"\\npretensions in asia and egypt, the grand style of architecture. it seems\\nthat in order to inscribe themselves upon the heart of humanity with\\neverlasting claims, all great things have first to wander about the\\nearth as enormous and awe-inspiring caricatures: dogmatic philosophy has\\nbeen a caricature of this kind--for instance, the vedanta doctrine in\\nasia, and platonism in europe. let us not be ungrateful to it, although\\nit must certainly be confessed that the worst, the most tiresome,\\nand the most dangerous of errors hitherto has been a dogmatist\\nerror--namely, plato\\'s invention of pure spirit and the good in itself.\\nbut now when it has been surmounted, when europe, rid of this nightmare,\\ncan again draw breath freely and at least enjoy a healthier--sleep,\\nwe, whose duty is wakefulness itself, are the heirs of all the strength\\nwhich the struggle against this error has fostered. it amounted to\\nthe very inversion of truth, and the denial of the perspective--the\\nfundamental condition--of life, to speak of spirit and the good as plato\\nspoke of them; indeed one might ask, as a physician: \"how did such a\\nmalady attack that finest product of antiquity, plato? had the wicked\\nsocrates really corrupted him? was socrates after all a corrupter of\\nyouths, and deserved his hemlock?\" but the struggle against plato,\\nor--to speak plainer, and for the \"people\"--the struggle against\\nthe ecclesiastical oppression of millenniums of christianity (for\\nchristianity is platonism for the \"people\"), produced in europe\\na magnificent tension of soul, such as had not existed anywhere\\npreviously; with such a tensely strained bow one can now aim at the\\nfurthest goals. as a matter of fact, the european feels this tension as\\na state of distress, and twice attempts have been made in grand style to\\nunbend the bow: once by means of jesuitism, and the second time by means\\nof democratic enlightenment--which, with the aid of liberty of the press\\nand newspaper-reading, might, in fact, bring it about that the spirit\\nwould not so easily find itself in \"distress\"! (the germans invented\\ngunpowder--all credit to them! but they again made things square--they\\ninvented printing.) but we, who are neither jesuits, nor democrats,\\nnor even sufficiently germans, we good europeans, and free, very free\\nspirits--we have it still, all the distress of spirit and all the\\ntension of its bow! and perhaps also the arrow, the duty, and, who\\nknows? the goal to aim at....\\n\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzazffZ8UPTj"
      },
      "source": [
        "## Listing 8.2 Downloading and parsing the initial text file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkQFYt_kS4lN",
        "outputId": "2028d930-a229-447c-e389-befa6fcfa854"
      },
      "source": [
        "import tensorflow\n",
        "import numpy as np\n",
        "path = tensorflow.keras.utils.get_file('nietzsche.txt',\n",
        "                            origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
        "\n",
        "text = open(path).read().lower()\n",
        "print('Corpus length:', len(text))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
            "606208/600901 [==============================] - 0s 1us/step\n",
            "Corpus length: 600893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJCYIbaqUh3K"
      },
      "source": [
        "## Listing 8.3 Vectorizing sequences of characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBJ611L4da0x"
      },
      "source": [
        "maxlen = 60\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "  sentences.append(text[i: i + maxlen])\n",
        "  next_chars.append(text[i + maxlen])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Sk4X3fVd3QO",
        "outputId": "6de7c3b7-1fc0-46e4-8413-677070364891"
      },
      "source": [
        "\n",
        "print('Number of sequences:', len(sentences))\n",
        "chars = sorted(list(set(text)))\n",
        "print('Unique characters:', len(chars))\n",
        "char_indices = dict((char, chars.index(char)) for char in chars)\n",
        "print('Vectorization...')\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sequences: 200278\n",
            "Unique characters: 57\n",
            "Vectorization...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbuET0_ZeYto",
        "outputId": "4c0de63d-02d7-452b-acfe-34dd6cc001fe"
      },
      "source": [
        "\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "\n",
        "y[2]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdHPeQbnUXzO"
      },
      "source": [
        "\n",
        "for i, sentence in enumerate(sentences):\n",
        "  for t, char in enumerate(sentence):\n",
        "    x[i, t, char_indices[char]] = 1\n",
        "  y[i, char_indices[next_chars[i]]] = 1"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aj6obGInerxM",
        "outputId": "87fdcf7b-b106-47d6-c347-836d6032edcd"
      },
      "source": [
        "y[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False,  True,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtBZbuADVODB"
      },
      "source": [
        "## Listing 8.4 Single-layer LSTM model for next-character prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN8Oce9_U-fM"
      },
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "model = keras.models.Sequential()\n",
        "model.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(layers.Dense(len(chars), activation='softmax'))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJsuqdILAi03",
        "outputId": "90b3f74f-c97d-4513-c45a-8341876f5c07"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 128)               95232     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 57)                7353      \n",
            "=================================================================\n",
            "Total params: 102,585\n",
            "Trainable params: 102,585\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16yfGWheVWBr"
      },
      "source": [
        "## Listing 8.5 Model compilation configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVcMhC6tVSl1"
      },
      "source": [
        "optimizer = keras.optimizers.RMSprop(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coKf816_V1et"
      },
      "source": [
        "## Listing 8.6 Function to sample the next character given the model’s predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdTI3vcTVZmu"
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "  preds = np.asarray(preds).astype('float64')\n",
        "  preds = np.log(preds) / temperature\n",
        "  exp_preds = np.exp(preds)\n",
        "  preds = exp_preds / np.sum(exp_preds)\n",
        "  probas = np.random.multinomial(1, preds, 1)\n",
        "  return np.argmax(probas)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kNfDmCJWAmR"
      },
      "source": [
        "## Listing 8.7 Text-generation loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sA4s-ik7bB7v",
        "outputId": "924a3a41-5c43-42e0-a0a6-5aefd6ee2655"
      },
      "source": [
        "import random\n",
        "import sys\n",
        "\n",
        "\n",
        "model.fit(x, y, batch_size=128, epochs=10)\n",
        "start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "generated_text = text[start_index: start_index + maxlen]\n",
        "print('--- Generating with seed: \"' + generated_text + '\"')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1565/1565 [==============================] - 30s 6ms/step - loss: 2.2503\n",
            "Epoch 2/10\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.6373\n",
            "Epoch 3/10\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.5240\n",
            "Epoch 4/10\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.4764\n",
            "Epoch 5/10\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.4368\n",
            "Epoch 6/10\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.4114\n",
            "Epoch 7/10\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.3991\n",
            "Epoch 8/10\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.3808\n",
            "Epoch 9/10\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.3728\n",
            "Epoch 10/10\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.3565\n",
            "--- Generating with seed: \"y becoming this or that. in the philosopher, on the\n",
            "contrary\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CskxCYNQcimq",
        "outputId": "2204f252-f003-47e6-e5b1-50b5d3e9a1ee"
      },
      "source": [
        "temperature = 0.5\n",
        "for i in range(400):\n",
        "    sampled = np.zeros((1, maxlen, len(chars)))\n",
        "    for t, char in enumerate(generated_text):\n",
        "      sampled[0, t, char_indices[char]] = 1.\n",
        "    preds = model.predict(sampled, verbose=0)[0]\n",
        "    next_index = sample(preds, temperature)\n",
        "    next_char = chars[next_index]\n",
        "    generated_text += next_char\n",
        "    generated_text = generated_text[1:]\n",
        "    sys.stdout.write(next_char)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " the experience to the fact the other to have the strong to how conscience of the conscien when the greater to its even of the stook of the extent consists healthing what it is a best and more that it is the same to me the earth. the more of conscience of the moral had it of the most conscience and all the experience and consequently orgent of the same time indifferent the destroy, the great think"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocrRoeAHBeZD",
        "outputId": "b2a9b185-0a0a-46f1-a4be-e0f65c85e985"
      },
      "source": [
        "temperature = 0.2\n",
        "for i in range(400):\n",
        "    sampled = np.zeros((1, maxlen, len(chars)))\n",
        "    for t, char in enumerate(generated_text):\n",
        "      sampled[0, t, char_indices[char]] = 1.\n",
        "    preds = model.predict(sampled, verbose=0)[0]\n",
        "    next_index = sample(preds, temperature)\n",
        "    next_char = chars[next_index]\n",
        "    generated_text += next_char\n",
        "    generated_text = generated_text[1:]\n",
        "    sys.stdout.write(next_char)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "s which have the world and the world to be conscience, and the whole the more and some the more the order to the world and conscience of the more the world and conscience of the more and the strong to the same the more the have the strong to the strong to strong the strong the strong to the conscience of the more and conscience of the reality of the strong the more the more and conscience of the m"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jXkGRR8BfZQ",
        "outputId": "d4301b8e-74f3-401c-d913-957dfda8d6c2"
      },
      "source": [
        "temperature = 0.1\n",
        "for i in range(400):\n",
        "    sampled = np.zeros((1, maxlen, len(chars)))\n",
        "    for t, char in enumerate(generated_text):\n",
        "      sampled[0, t, char_indices[char]] = 1.\n",
        "    preds = model.predict(sampled, verbose=0)[0]\n",
        "    next_index = sample(preds, temperature)\n",
        "    next_char = chars[next_index]\n",
        "    generated_text += next_char\n",
        "    generated_text = generated_text[1:]\n",
        "    sys.stdout.write(next_char)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ore the world and the more the strong to the strong to the strong to the strong to the strong to the strong the more the strong the more the strong the strong to the strong to the strong to the strong to the strong the more the more the more the more the more and strong to the strong to the strong to the strong to the strong to the strong to the strong to the strong to the strong to the strong to "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G49RqUssV5i3",
        "outputId": "f2fe41e5-c009-4051-813b-20b21b6853f9"
      },
      "source": [
        "import random\n",
        "import sys\n",
        "\n",
        "for epoch in range(1, 60):\n",
        "  print('epoch', epoch)\n",
        "  model.fit(x, y, batch_size=128, epochs=1)\n",
        "  start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "  generated_text = text[start_index: start_index + maxlen]\n",
        "  print('--- Generating with seed: \"' + generated_text + '\"')\n",
        "\n",
        "for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
        "  print('------ temperature:', temperature)\n",
        "  sys.stdout.write(generated_text)\n",
        "  for i in range(400):\n",
        "    sampled = np.zeros((1, maxlen, len(chars)))\n",
        "    for t, char in enumerate(generated_text):\n",
        "      sampled[0, t, char_indices[char]] = 1.\n",
        "    preds = model.predict(sampled, verbose=0)[0]\n",
        "    next_index = sample(preds, temperature)\n",
        "    next_char = chars[next_index]\n",
        "    generated_text += next_char\n",
        "    generated_text = generated_text[1:]\n",
        "    sys.stdout.write(next_char)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.3681\n",
            "--- Generating with seed: \"s, as it were, clad his philosophy in mail and\n",
            "mask--in fact\"\n",
            "epoch 2\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.3602\n",
            "--- Generating with seed: \"stem of interpretation as artificial and exaggerated\n",
            "as the \"\n",
            "epoch 3\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.3537\n",
            "--- Generating with seed: \"every \"science of morals\"\n",
            "hitherto, strange as it may sound,\"\n",
            "epoch 4\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.3460\n",
            "--- Generating with seed: \" terms, an enemy and\n",
            "challenger of god; and whosoever has ex\"\n",
            "epoch 5\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.3427\n",
            "--- Generating with seed: \"n human herds (family alliances, communities, tribes, people\"\n",
            "epoch 6\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.3365\n",
            "--- Generating with seed: \"patriotism, a plunge and relapse into old loves and narrow\n",
            "v\"\n",
            "epoch 7\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.3319\n",
            "--- Generating with seed: \" not those sincere and massive virtues on\n",
            "account of which w\"\n",
            "epoch 8\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.3282\n",
            "--- Generating with seed: \"t present sprawls\n",
            "in the foreground--it recently celebrated \"\n",
            "epoch 9\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.3245\n",
            "--- Generating with seed: \" almost\n",
            "instinctively in \"progress\" and the \"future,\" and ar\"\n",
            "epoch 10\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.3212\n",
            "--- Generating with seed: \"of the attention, the straight look which fixes itself\n",
            "exclu\"\n",
            "epoch 11\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.3183\n",
            "--- Generating with seed: \", oh, heart;--\n",
            "                     strong was thy hope;\n",
            "   \"\n",
            "epoch 12\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.3158\n",
            "--- Generating with seed: \"y; yet it seems as if it were hardly commenced. is\n",
            "it any wo\"\n",
            "epoch 13\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.3115\n",
            "--- Generating with seed: \" after the fabric of society seems on the\n",
            "whole established \"\n",
            "epoch 14\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.3079\n",
            "--- Generating with seed: \" that roguish and cheerful vice,\n",
            "politeness. and to remain m\"\n",
            "epoch 15\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.3044\n",
            "--- Generating with seed: \"anity gave eros poison to drink; he did not die of it,\n",
            "certa\"\n",
            "epoch 16\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.3024\n",
            "--- Generating with seed: \"mselves yet higher to the blue,\n",
            "     to spy for you from far\"\n",
            "epoch 17\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2987\n",
            "--- Generating with seed: \"velty which is not unensnaring, and might\n",
            "perhaps arouse sus\"\n",
            "epoch 18\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2963\n",
            "--- Generating with seed: \"s. the\n",
            "noble soul gives as he takes, prompted by the passion\"\n",
            "epoch 19\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2955\n",
            "--- Generating with seed: \", during a long period, and persistently, wishes to appear\n",
            "s\"\n",
            "epoch 20\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2952\n",
            "--- Generating with seed: \"e recognized as the queen of the sciences,\n",
            "for whose service\"\n",
            "epoch 21\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2897\n",
            "--- Generating with seed: \"communities, tribes, peoples,\n",
            "states, churches), and always \"\n",
            "epoch 22\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2871\n",
            "--- Generating with seed: \"ise the countries where european influence\n",
            "prevails in europ\"\n",
            "epoch 23\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2879\n",
            "--- Generating with seed: \"nsible to the higher, finer impulses which the\n",
            "present civil\"\n",
            "epoch 24\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2833\n",
            "--- Generating with seed: \"and women--that the terrible\n",
            "seriousness and clumsy importun\"\n",
            "epoch 25\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2821\n",
            "--- Generating with seed: \"dren\n",
            "their parents, pupils their teacher, and well disposed \"\n",
            "epoch 26\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2814\n",
            "--- Generating with seed: \"f all sorts. in the first case, when it is\n",
            "the rulers who de\"\n",
            "epoch 27\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2801\n",
            "--- Generating with seed: \"nt, very complaisant--but with all this we are\n",
            "perhaps not v\"\n",
            "epoch 28\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2773\n",
            "--- Generating with seed: \"et and forgotten, in its old\n",
            "corner.--one ought to learn ane\"\n",
            "epoch 29\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2745\n",
            "--- Generating with seed: \"nd the fact that it is\n",
            "an elsewhere,[6] another sphere, inac\"\n",
            "epoch 30\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2746\n",
            "--- Generating with seed: \"eir satisfaction with the actual world in which they find it\"\n",
            "epoch 31\n",
            "1565/1565 [==============================] - 10s 7ms/step - loss: 1.2721\n",
            "--- Generating with seed: \"ch a thing--has to do not with its nature but with its\n",
            "propa\"\n",
            "epoch 32\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2696\n",
            "--- Generating with seed: \"ity and irresponsibility. this depression, indeed, is due\n",
            "ap\"\n",
            "epoch 33\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2701\n",
            "--- Generating with seed: \"ilt up: the\n",
            "individual promotes his own salvation; when, for\"\n",
            "epoch 34\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2669\n",
            "--- Generating with seed: \". in order to understand stoicism, or port royal,\n",
            "or puritan\"\n",
            "epoch 35\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2662\n",
            "--- Generating with seed: \"arch, erasmus,\n",
            "voltaire. we have taken a forward step out of\"\n",
            "epoch 36\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2647\n",
            "--- Generating with seed: \"ot ask me who;\n",
            "     at midday 'twas, when one became as two.\"\n",
            "epoch 37\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2630\n",
            "--- Generating with seed: \"trarily and falsely misinterpreted. with all\n",
            "the more profou\"\n",
            "epoch 38\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2626\n",
            "--- Generating with seed: \"some solitude, which also gives you the right still to\n",
            "remai\"\n",
            "epoch 39\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2607\n",
            "--- Generating with seed: \", either\n",
            "consciously or unconsciously, hypocrites, and final\"\n",
            "epoch 40\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2600\n",
            "--- Generating with seed: \"y\n",
            "which knows that it is authorized to maintain gradations o\"\n",
            "epoch 41\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2595\n",
            "--- Generating with seed: \"ervable how the less reflective free spirits collide only wi\"\n",
            "epoch 42\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2606\n",
            "--- Generating with seed: \"-how often and easily they make mistakes and lose their way,\"\n",
            "epoch 43\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2593\n",
            "--- Generating with seed: \"y! why did\n",
            "we choose it, this foolish task? or, to put the q\"\n",
            "epoch 44\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2566\n",
            "--- Generating with seed: \"njoyments itself is not determined according to absolute eth\"\n",
            "epoch 45\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2530\n",
            "--- Generating with seed: \"one another. in the new\n",
            "generation, which has inherited as i\"\n",
            "epoch 46\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2539\n",
            "--- Generating with seed: \"itful and barren and uncertain:\n",
            "imagine to yourselves indiff\"\n",
            "epoch 47\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2509\n",
            "--- Generating with seed: \" the conditions under which, climatically and\n",
            "hereditarily, \"\n",
            "epoch 48\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2510\n",
            "--- Generating with seed: \":--a self-control, to be sure, which offers excellent\n",
            "opport\"\n",
            "epoch 49\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2475\n",
            "--- Generating with seed: \"stition, which, in the form of subject- and\n",
            "ego-superstition\"\n",
            "epoch 50\n",
            "1565/1565 [==============================] - 10s 7ms/step - loss: 1.2481\n",
            "--- Generating with seed: \"t the knowledge that another suffers on\n",
            "our account here, in\"\n",
            "epoch 51\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2479\n",
            "--- Generating with seed: \"arth-residuum, and particle-atom: it is the greatest\n",
            "triumph\"\n",
            "epoch 52\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2462\n",
            "--- Generating with seed: \"e production of a type prepared for slavery in the most subt\"\n",
            "epoch 53\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2476\n",
            "--- Generating with seed: \"\n",
            "celebrated \"metaphysical requirements\": one must also above\"\n",
            "epoch 54\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2466\n",
            "--- Generating with seed: \"e knife and tweezers entailed by the process, can no\n",
            "longer \"\n",
            "epoch 55\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2458\n",
            "--- Generating with seed: \"tianity of calderon this thought is again perverted and\n",
            "enta\"\n",
            "epoch 56\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2439\n",
            "--- Generating with seed: \"w as the basis of all existing religions and metaphysics,\n",
            "th\"\n",
            "epoch 57\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2447\n",
            "--- Generating with seed: \" as conducive to the general welfare) wants to have\n",
            "any know\"\n",
            "epoch 58\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2435\n",
            "--- Generating with seed: \"'--that is their devilry, and nothing else!\"\n",
            "what does it ma\"\n",
            "epoch 59\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2416\n",
            "--- Generating with seed: \"side entirely the blundering psychology of\n",
            "former times, whi\"\n",
            "------ temperature: 0.2\n",
            "side entirely the blundering psychology of\n",
            "former times, which as a soul and "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "in the spirit of the present the most some the strength and the same to the experience, and the superficial and the sure of the most desire and in the strength and in the strength and the surent and propided to be a man with the present the present in the same to be a desires to the strength and something with the taste of the man was the same to be a disconer and conscience of th------ temperature: 0.5\n",
            "f the man was the same to be a disconer and conscience of the ears of the most instincts, whoever all the same still the one will laws,ain, to be one is respect that a soul, who are extent of the general and the personal evilst and the unconditions and conscience of the dispense and one who an innoces only and sympathy and conscience and passions are may be hand, in still taste,\n",
            "the most egoists and the conscience and even of the stom before a new contain ------ temperature: 1.0\n",
            "nd the conscience and even of the stom before a new contain that for it is\n",
            "let an important to ymanting down\n",
            "inderdipsus.\n",
            ".\n",
            "         as be\n",
            "men of my, without domantful. so best\n",
            "from suffers that the impulse just altoct merely for our instinct\n",
            "may is realized the same souls of present discordenly the cood and concerncilate suporaried in\n",
            "the first\n",
            "myrearing for\n",
            "the indiviguatmentness, aagablem in ordous\n",
            "infering ancis, for his own\n",
            "colled, and alone with all ------ temperature: 1.2\n",
            "dous\n",
            "infering ancis, for his own\n",
            "colled, and alone with all aistle\n",
            "races of placed fores\" in impulse of youth, tisticed by everything, let\n",
            "metaphysictsy, and time-eche dong them belotged in effering in an\" nature, instinct butreature sympathy?\n",
            "\n",
            "1\n",
            "oæus\n",
            "too evil thought upeter)nee; he exaggerated cast theirman,\n",
            "one contempocalities: every ferisy, habdly need over these weat, mahletry, hod, vour and\n",
            "sacy to their dven men. if onress. at oub and htindcy\n",
            "conity"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9PehOkAWmtn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f41b844-1e14-4245-abb7-6dd9ff9b2a20"
      },
      "source": [
        "model.save(\"text_generator_1\")\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: text_generator_1/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: text_generator_1/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfwkUru4GkZY"
      },
      "source": [
        "model.save_weights(\"text_generator_checkpoints\")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSltfslWHWfJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}